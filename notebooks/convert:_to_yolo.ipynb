{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import json\n",
    "import shutil\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import cv2\n",
    "from warnings import warn\n",
    "\n",
    "\n",
    "def swap_file_structure(target_dir: str, source_dir: str, img_size: int = 960):\n",
    "    \"\"\"\n",
    "    This function will take the PVDN dataset file structure and create the file & annotation\n",
    "    structure required by yolov5.\n",
    "    :param target_dir: Directory where the new yolo file structure is supposed to be created.\n",
    "    :param source_dir: Base directory of the original PVDN dataset.\n",
    "    :param img_size: The final size of the image to be fed into the yolo network. The image will\n",
    "        have to be square, so it will have the size img_size x img_size. The default value is 960.\n",
    "    \"\"\"\n",
    "    target_dir = os.path.abspath(target_dir)\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "    # paranoid checks\n",
    "    if not os.path.isdir(source_dir):\n",
    "        raise NotADirectoryError(f\"{source_dir} is not a directory. Please check.\")\n",
    "    if not os.path.isdir(target_dir):\n",
    "        raise NotADirectoryError(f\"{target_dir} is not a directory. Please check.\")\n",
    "\n",
    "\n",
    "    print(os.path.isdir(os.path.join(source_dir, \"train/labels/kpbms_boxes\")))\n",
    "    print(os.path.isdir(os.path.join(source_dir, \"test/labels/kpbms_boxes\")))\n",
    "    print(os.path.isdir(os.path.join(source_dir, \"val/labels/kpbms_boxes\")))\n",
    "    # check if the bounding box annotations have actually been created before\n",
    "    if not os.path.isdir(os.path.join(source_dir, \"train/labels/kpbms_boxes\")) \\\n",
    "        or not os.path.isdir(os.path.join(source_dir, \"test/labels/kpbms_boxes\"))\\\n",
    "        or not os.path.isdir(os.path.join(source_dir, \"val/labels/kpbms_boxes\")):\n",
    "        raise FileNotFoundError(\"The bounding box annotations could not be found. \"\n",
    "                                \"Please check if you have generated them yet. You \"\n",
    "                                \"can generate them by using the \"\n",
    "                                \"generate_bounding_boxes() method from the \"\n",
    "                                \"BoundingBoxDataset class in pvdn/bboxes.py.\")\n",
    "\n",
    "\n",
    "    num_classes = 1\n",
    "    names = ['instance']\n",
    "\n",
    "    overview = {\n",
    "        \"train\": os.path.join(target_dir, \"train\"),\n",
    "        \"val\": os.path.join(target_dir, \"val\"),\n",
    "        \"test\": os.path.join(target_dir, \"test\"),\n",
    "        \"nc\": num_classes,\n",
    "        \"names\": names\n",
    "    }\n",
    "\n",
    "    # create .yaml file required for yolo training\n",
    "    yaml_dir = os.path.join(target_dir, 'pvdn.yaml')\n",
    "    print(f\"Creating yolo .yaml file at {yaml_dir}...\")\n",
    "    with open(yaml_dir, \"w\") as f:\n",
    "        yaml.dump(overview, f, default_flow_style=None)\n",
    "\n",
    "    # doing conversion for each split\n",
    "    splits = (\"train\", \"test\", \"val\")\n",
    "    for split in splits:\n",
    "\n",
    "        # checking & setting up paths\n",
    "        target_path = os.path.join(target_dir, split)\n",
    "        source_path = os.path.join(source_dir, split)\n",
    "        if not os.path.isdir(source_path):\n",
    "            warn(f\"{source_path} does not exist or is not a directory. Skipping the {split} split.\")\n",
    "            continue\n",
    "        os.makedirs(target_path, exist_ok=True)\n",
    "\n",
    "        print(f\"Copying {split} images to {target_path}.\")\n",
    "        scenes_dir = os.path.join(source_path, \"images\")\n",
    "        scenes = os.listdir(scenes_dir)\n",
    "        for scene in tqdm(scenes, desc=f\"Running through scenes of the {split} split\"):\n",
    "            images = os.listdir(os.path.join(scenes_dir, scene))\n",
    "            for img in images:\n",
    "                # resize image to be square (img_size x img_size)\n",
    "                im = cv2.imread(os.path.join(scenes_dir, scene, img), 0)\n",
    "                h_orig, w_orig = im.shape\n",
    "                im = cv2.resize(im, (img_size, img_size), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "                # save image to new location\n",
    "                cv2.imwrite(os.path.join(target_path, img), im)\n",
    "                if not os.path.exists(os.path.join(target_path, img)):\n",
    "                    shutil.copy(os.path.join(scenes_dir, scene, img), target_path)\n",
    "\n",
    "                # create annotation file\n",
    "                annot_file = img.split(\".\")[0] + \".json\"\n",
    "                with open(os.path.join(source_dir, split, \"labels\", \"kpbms_boxes\",\n",
    "                                       annot_file), \"r\") as f:\n",
    "                    annot = json.load(f)\n",
    "\n",
    "                annot[\"bounding_boxes\"] = np.array(annot[\"bounding_boxes\"])\n",
    "                annot[\"labels\"] = np.array(annot[\"labels\"])\n",
    "                deletes = np.where(annot[\"labels\"] == 0)\n",
    "                annot[\"bounding_boxes\"] = np.delete(annot[\"bounding_boxes\"], deletes, axis=0)\n",
    "                annot[\"labels\"] = np.delete(annot[\"labels\"], deletes)\n",
    "\n",
    "                yolo_file = img.split(\".\")[0] + \".txt\"\n",
    "                if os.path.exists(os.path.join(target_path, yolo_file)):\n",
    "                    os.remove(os.path.join(target_path, yolo_file))\n",
    "                if len(annot[\"labels\"]) > 0:\n",
    "                    with open(os.path.join(target_path, yolo_file), \"w\") as f:\n",
    "                        for box, label in zip(annot[\"bounding_boxes\"], annot[\"labels\"]):\n",
    "                            box = np.array(box, dtype=float)\n",
    "                            new_box = box.copy()\n",
    "                            new_box[:2] += (box[2:] - box[:2]) / 2  # make center\n",
    "                            new_box[2:] -= box[:2]  # make height/width\n",
    "                            new_box[0] /= w_orig\n",
    "                            new_box[2] /= w_orig\n",
    "                            new_box[1] /= h_orig\n",
    "                            new_box[3] /= h_orig\n",
    "                            line = [0] + new_box.tolist()\n",
    "                            line = [str(e) for e in line]\n",
    "                            line = \" \".join(line)\n",
    "                            f.write(line)\n",
    "                            f.write(\"\\n\")\n",
    "\n",
    "    print(\"Finished successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "Creating yolo .yaml file at /raid/datasets/PVDN_Dataset/yolo_saliency_whole_scene_optimized/day/pvdn.yaml...\n",
      "Copying train images to /raid/datasets/PVDN_Dataset/yolo_saliency_whole_scene_optimized/day/train.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through scenes of the train split: 100%|██████████| 113/113 [06:33<00:00,  3.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying test images to /raid/datasets/PVDN_Dataset/yolo_saliency_whole_scene_optimized/day/test.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through scenes of the test split: 100%|██████████| 19/19 [01:04<00:00,  3.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying val images to /raid/datasets/PVDN_Dataset/yolo_saliency_whole_scene_optimized/day/val.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running through scenes of the val split: 100%|██████████| 20/20 [01:19<00:00,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "source_dir = \"/raid/datasets/PVDN_Dataset/PVDN/day/\"\n",
    "target_dir = \"/raid/datasets/PVDN_Dataset/yolo_saliency_single_scene_optimized/day\"\n",
    "img_size = 960\n",
    "\n",
    "print(os.path.isdir(os.path.join(source_dir, \"train/labels/kpbms_boxes\")))\n",
    "print(os.path.isdir(os.path.join(source_dir, \"test/labels/kpbms_boxes\")))\n",
    "print(os.path.isdir(os.path.join(source_dir, \"val/labels/kpbms_boxes\")))\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "swap_file_structure(target_dir, source_dir, img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd83d03af66c195f89e0c87dcaf1f3bf507dd9fd683146231c4851f90a7e03ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
